========================
TODOs für die uap v0.0.2
========================

uap <project>.yaml volatilize Probleme (Done)
---------------------------------------------

* volatilize Subcommand reparieren:
** kein automatisches volatilisieren
** korrektes markieren von mehreren aufeinanderfolgenden volatilisierten Runs
   wenn ein neuer Step angehangen wird.

Zombie-Prozesse? (Don't do)
---------------------------

* uap scheint Prozesse zu erzeugen die weiterlaufen nachdem der Hauptprozesse
  getötet wurde. Warum werden die Kinderprozesse nicht gestoppt wenn der Eltern
  Prozess gestoppt wird?

Zusammenspiel von <project>.yaml und Submit Script Template (Christoph)
-----------------------------------------------------------------------

* in der Project Config kann man folgendes angeben:

cluster:
    default_submit_options: "-pe smp #{CORES} -cwd -S /bin/bash -m as -l h_rt=48:00:00 -l h_vmem=4G"
    default_pre_job_command: "module ..."
    default_post_job_command: "module ..."
    default_job_quota: <int>

** Pro Step kann man die default Werte überschreiben:

steps:
    step_a:
        _cluster_submit_options: "..."
        _cluster_pre_job_command: "..."
        _cluster_post_job_command: "..."

*** die default Werte zu überschreiben


!!!
    Die folgende Idee ist nicht umsetzbar, ohne die Nutzbarkeit auf den
    Frontend Nodes massiv zu beeinträchtigen. Außerdem baut uap bei jedem
    Aufruf den kompletten DAG auf und dafür checkt er die Verfügbarkeit aller
    Tools. Das würde zwangsläufig crashen wenn wir diese Änderung einführen,
    da nur die Tools für den auszuführenden Step/Run geladen werden würden.
!!!
** Pro Tool sollte es die Möglichkeit geben:
*** ein module load/unload Kommando anzugeben das dann einfach in das
    Submit Skript Template geschrieben wird

Cluster Config als separate YAML Datei (Done)
---------------------------------------------

Die Cluster Config ist aktuell ein hart-kodiertes Dictionary in
pipeline.py, das sollte am besten überführt werden in eine YAML
Konfigurationsdatei. (Hab ich gemacht. CK) Plus Doku.


s2c.py (Sven + Gero) Done
-------------------------

Bitte Error Messages ins Englische übersetzen. (Done by Gero)
Die Lösung mit s2c.py und fix_s2c.py bleibt erhalten. (Done)

Dokumentation (Alexander + Christoph + Sven)
--------------------------------------------

Es wäre super wenn wir eine FAQ Seite für die häufigsten
Fehlermeldungen haben würden (für Alexander aber auch alle anderen).
Die Doku des fastq_source Steps sollte ein Beispiel für ein YAML
dictionary enthalten.
Generell muss die Doku auf fehlenden Inhalt Kontroll gelesen werden.

SHAsum für alle Ausgabedateien (Christoph) (Done)
-------------------------------------------------

Wollen wir das jetzt für alle erzeugten Ausgabedaten. (Done)
SHA1sum für Output Dateien in der Annotation (Done).

Docker (Alexander/Christoph) (Geringste Prio)
---------------------------------------------

Docker Support einbauen mittels Dockerfiles. Sitze ich gerade dran (Christoph).

Pfadangaben für Dateien die aus uap geladen werden (Sven)
---------------------------------------------------------

absolute Pfadangaben für alle open() calls.


Debugging (???)
---------------

Submit Script in Annotation Datei speichern. (Done)
Prosa Log nach STDERR mittels logger 
Evtl. Subcommand fürs zusammensuchen von Ausgabedaten des Runs.

Weitere Ideen
-------------

* Verteilen von uap über PyPI (Python Package Repos)


Mailinglist/GitHub Issue Tracker
--------------------------------

* Vorbereiten das wir für Fehlermeldungen erreichbar sind












RNASeq Pipeline Meeting 2014/04/29
----------------------------------

Sven, Jörg, Kristin, Christoph, Micha

Tasks:

- interactive tool to handle big config files might be helpful <least concern>
- add more options to steps with default values which may be adjusted by users
  (for example cufflinks), also add corresponding command line switches
- status.py: add option to skip tool checking, find out why it's so slow (fstat?)
  <solved>
- is it possible to watch a processes' stderr while a step is running?
  - preferably not only if you launched in debug mode, but always, like inter-
  cepting write calls to the respective file descriptor
  - or maybe dump each monitored file's 1024 byte tail every once in a while 
  (this would be easiest and includes stdout and stderr)
- clean up in/ and out/ names - 'error', 'log', 'stderr' should in some cases
  become the same thing
  - we need a well-defined ontology of file types regardless of actual file
  type, more from the semantic perspective
- add a random suffix to SGE's stdout and stderr log filenames

Problems:
- if different sources contain identically named samples they are probably gone
  overwrite there output files handled wrong
  
Sequencing Workflows
====================

Reference Genome
----------------

* Genome Resequencing
** Variant Calling

* Methylome
** Specific alignment (Bisulfite converted bases)
** Methylation calling

* Transcriptome
** De-novo transcript assembly
** Counts per annotation
** Differential expression

* ChIP-seq
** aggregate to peaks
** peak calling (foreground vs background)

Non-reference Genome
--------------------

* Genome
** Genome Assembly

* Transcriptome
** Assemble Transcripts
