========================
TODOs für die uap v0.0.2
========================

uap <project>.yaml volatilize Probleme
--------------------------------------

* volatilize Subcommand reparieren (DONE):
** kein automatisches volatilisieren
** korrektes markieren von mehreren aufeinanderfolgenden volatilisierten Runs
   wenn ein neuer Step angehangen wird.

Zombie-Prozesse? (???)
----------------------

* uap scheint Prozesse zu erzeugen die weiterlaufen nachdem der Hauptprozesse
  getötet wurde. Warum werden die Kinderprozesse nicht gestoppt wenn der Eltern
  Prozess gestoppt wird?


Zusammenspiel von <project>.yaml und Submit Script Template (Christoph)
-----------------------------------------------------------------------

* Überarbeiten der Config und der Submit Script Templates
** in der Config sollte man folgendes angeben können:
*** default submit_options
*** default pre_job_commands
*** default post_job_commands
*** job_quota default Werte
** Pro Step sollte man die Möglichkeit haben:
*** die default Werte zu überschreiben
** Pro Tool sollte es die Möglichkeit geben:
*** ein module load/unload Kommando anzugeben das dann einfach in das
*Submit Skript Template geschrieben wird

Andere Idee:
* Default Template und optionale Templates


Cluster Config als separate YAML Datei (Sven)
---------------------------------------------

Die Cluster Config ist aktuell ein hart-kodiertes Dictionary in
pipeline.py, das sollte am besten überführt werden in eine YAML
Konfigurationsdatei. Plus Doku.

s2c.py (Sven + Gero)
--------------------

Bitte Error Messages ins Englische übersetzen.
Außerdem wäre es super wenn wir uns für eine Variante entscheiden
würden wie wir die Konvertierung von segemehl output zu cufflinks
durchführen wollen.
Aktuell haben wir mehrere Möglichkeiten:

* make_segemehl_output_cufflinks_compatible.py (f.k.a. s2c.py)
* fix_make_segemehl_output_cufflinks_compatible.py (f.k.a. fix_s2c.py)
* post_sawdust.py (Merge der beiden vorgenannten?)

Sven würde gerne alle Tools aus uap rausschmiessen und die über Git
Repos etc. holen.

Dokumentation (Alexander + Christoph + Sven)
--------------------------------------------

Es wäre super wenn wir eine FAQ Seite für die häufigsten
Fehlermeldungen haben würden (für Alexander aber auch alle anderen).
Die Doku des fastq_source Steps sollte ein Beispiel für ein YAML
dictionary enthalten.
Generell muss die Doku auf fehlenden Inhalt Kontroll gelesen werden.

SHAsum für nicht nicht-gepippte Ausgabedateien (Christoph)
----------------------------------------------------------

Wollen wir das jetzt für alle erzeugten Ausgabedaten. (Ja)
SHAsum einmal in der Annotation und in separater SHAsum Datei.

PyPI (least concern)
---------------------

Distribution über Python Package Repos

Docker (Alexander)
------------------

Docker Support einbauen mittels Dockerfiles

Pfadangaben für Dateien die aus uap geladen werden (Sven)
---------------------------------------------------------

absolute Pfadangaben für alle open() calls.


Debugging (???)
---------------

Evtl. Subcommand fürs zusammensuchen von Ausgabedaten des Runs.

Mailinglist/GitHub Issue Tracker
--------------------------------

* Vorbereiten das wir für Fehlermeldungen erreichbar sind

=========================
Deadline für uap Bugfixes
=========================

**14.07.16**
























RNASeq Pipeline Meeting 2014/04/29
----------------------------------

Sven, Jörg, Kristin, Christoph, Micha

Tasks:

- implement SLURM support <moved to AG>
- interactive tool to handle big config files might be helpful <least concern>
- add more options to steps with default values which may be adjusted by users
  (for example cufflinks), also add corresponding command line switches
- don't hard-code CPU & RAM requirements, both should be configurable per step
  - also define global CPU & RAM limits in the configuration
- don't hard-code modules, define which modules are required for which tool in
  the config
- status.py: add option to skip tool checking, find out why it's so slow (fstat?)
  <solved>
- are multiple output files per out/ connection possible?
  <yes>
- add ''-joined process args string to YAML log file to facilitate manual re-runs
  <should be output by option to status.py>
- is it possible to watch a processes' stderr while a step is running?
  - preferably not only if you launched in debug mode, but always, like inter-
  cepting write calls to the respective file descriptor
  - or maybe dump each monitored file's 1024 byte tail every once in a while 
  (this would be easiest and includes stdout and stderr)
- clean up in/ and out/ names - 'error', 'log', 'stderr' should in some cases
  become the same thing
  - we need a well-defined ontology of file types regardless of actual file
  type, more from the semantic perspective
- fix quoting in result graph rendering (when " appears in a command line, the 
  dot file gets messed up)
- add a random suffix to SGE's stdout and stderr log filenames
- information about created public_info should be better documented
  <documentation per step should be generally better>

Problems:
- if different sources contain identically named samples they are probably gone
  overwrite there output files handled wrong
  
Sequencing Workflows
====================

Reference Genome
----------------

* Genome Resequencing
** Variant Calling

* Methylome
** Specific alignment (Bisulfite converted bases)
** Methylation calling

* Transcriptome
** De-novo transcript assembly
** Counts per annotation
** Differential expression

* ChIP-seq
** aggregate to peaks
** peak calling (foreground vs background)

Non-reference Genome
--------------------

* Genome
** Genome Assembly

* Transcriptome
** Assemble Transcripts
