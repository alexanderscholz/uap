========================
TODOs für die uap v0.0.2
========================

uap <project>.yaml volatilize Probleme (Done)
---------------------------------------------

* volatilize Subcommand reparieren:
** kein automatisches volatilisieren
** korrektes markieren von mehreren aufeinanderfolgenden volatilisierten Runs
   wenn ein neuer Step angehangen wird.

Zombie-Prozesse? (???)
----------------------

* uap scheint Prozesse zu erzeugen die weiterlaufen nachdem der Hauptprozesse
  getötet wurde. Warum werden die Kinderprozesse nicht gestoppt wenn der Eltern
  Prozess gestoppt wird?


Zusammenspiel von <project>.yaml und Submit Script Template (Christoph)
-----------------------------------------------------------------------

* Überarbeiten der Config und der Submit Script Templates
** in der Config sollte man folgendes angeben können:
*** default submit_options
*** default pre_job_commands
*** default post_job_commands
*** job_quota default Werte
** Pro Step sollte man die Möglichkeit haben:
*** die default Werte zu überschreiben
!!! 
    Die folgende Idee ist nicht umsetzbar, ohne die Nutzbarkeit auf den
    Frontend Nodes massiv zu beeinträchtigen.
!!!
** Pro Tool sollte es die Möglichkeit geben:
*** ein module load/unload Kommando anzugeben das dann einfach in das
    Submit Skript Template geschrieben wird

Andere Idee:
* Default Template und optionale Templates


Cluster Config als separate YAML Datei (Sven) Done by (Christoph)
-----------------------------------------------------------------

Die Cluster Config ist aktuell ein hart-kodiertes Dictionary in
pipeline.py, das sollte am besten überführt werden in eine YAML
Konfigurationsdatei. (Hab ich gemacht. CK) Plus Doku.


s2c.py (Sven + Gero) Done
-------------------------

Bitte Error Messages ins Englische übersetzen. (Done by Gero)
Die Lösung mit s2c.py und fix_s2c.py bleibt erhalten. (Done)

Dokumentation (Alexander + Christoph + Sven)
--------------------------------------------

Es wäre super wenn wir eine FAQ Seite für die häufigsten
Fehlermeldungen haben würden (für Alexander aber auch alle anderen).
Die Doku des fastq_source Steps sollte ein Beispiel für ein YAML
dictionary enthalten.
Generell muss die Doku auf fehlenden Inhalt Kontroll gelesen werden.

SHAsum für nicht nicht-gepipte Ausgabedateien (Christoph)
---------------------------------------------------------

Wollen wir das jetzt für alle erzeugten Ausgabedaten. (Ja)
SHAsum einmal in der Annotation und in separater SHAsum Datei.

PyPI (least concern)
---------------------

Distribution über Python Package Repos

Docker (Alexander/Christoph) 
----------------------------

Docker Support einbauen mittels Dockerfiles. Sitze ich gerade dran (Christoph).

Pfadangaben für Dateien die aus uap geladen werden (Sven)
---------------------------------------------------------

absolute Pfadangaben für alle open() calls.


Debugging (???)
---------------

Evtl. Subcommand fürs zusammensuchen von Ausgabedaten des Runs.

Mailinglist/GitHub Issue Tracker
--------------------------------

* Vorbereiten das wir für Fehlermeldungen erreichbar sind

=========================
Deadline für uap Bugfixes
=========================

**14.07.16**
























RNASeq Pipeline Meeting 2014/04/29
----------------------------------

Sven, Jörg, Kristin, Christoph, Micha

Tasks:

- implement SLURM support <moved to AG>
- interactive tool to handle big config files might be helpful <least concern>
- add more options to steps with default values which may be adjusted by users
  (for example cufflinks), also add corresponding command line switches
- don't hard-code CPU & RAM requirements, both should be configurable per step
  - also define global CPU & RAM limits in the configuration
- don't hard-code modules, define which modules are required for which tool in
  the config
- status.py: add option to skip tool checking, find out why it's so slow (fstat?)
  <solved>
- are multiple output files per out/ connection possible?
  <yes>
- add ''-joined process args string to YAML log file to facilitate manual re-runs
  <should be output by option to status.py>
- is it possible to watch a processes' stderr while a step is running?
  - preferably not only if you launched in debug mode, but always, like inter-
  cepting write calls to the respective file descriptor
  - or maybe dump each monitored file's 1024 byte tail every once in a while 
  (this would be easiest and includes stdout and stderr)
- clean up in/ and out/ names - 'error', 'log', 'stderr' should in some cases
  become the same thing
  - we need a well-defined ontology of file types regardless of actual file
  type, more from the semantic perspective
- fix quoting in result graph rendering (when " appears in a command line, the 
  dot file gets messed up)
- add a random suffix to SGE's stdout and stderr log filenames
- information about created public_info should be better documented
  <documentation per step should be generally better>

Problems:
- if different sources contain identically named samples they are probably gone
  overwrite there output files handled wrong
  
Sequencing Workflows
====================

Reference Genome
----------------

* Genome Resequencing
** Variant Calling

* Methylome
** Specific alignment (Bisulfite converted bases)
** Methylation calling

* Transcriptome
** De-novo transcript assembly
** Counts per annotation
** Differential expression

* ChIP-seq
** aggregate to peaks
** peak calling (foreground vs background)

Non-reference Genome
--------------------

* Genome
** Genome Assembly

* Transcriptome
** Assemble Transcripts
