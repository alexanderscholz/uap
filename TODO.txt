========================
TODOs für die uap v0.0.2
========================

uap <project>.yaml volatilize Probleme (Done)
---------------------------------------------

* volatilize Subcommand reparieren:
** kein automatisches volatilisieren
** korrektes markieren von mehreren aufeinanderfolgenden volatilisierten Runs
   wenn ein neuer Step angehangen wird.

Zombie-Prozesse? (Don't do)
---------------------------

* uap scheint Prozesse zu erzeugen die weiterlaufen nachdem der Hauptprozesse
  getötet wurde. Warum werden die Kinderprozesse nicht gestoppt wenn der Eltern
  Prozess gestoppt wird?

Zusammenspiel von <project>.yaml und Submit Script Template (Christoph)
-----------------------------------------------------------------------

* in der Project Config kann man folgendes angeben:

cluster:
    default_submit_options: "-pe smp #{CORES} -cwd -S /bin/bash -m as -l h_rt=48:00:00 -l h_vmem=4G"
    default_pre_job_command: "module ..."
    default_post_job_command: "module ..."
    default_job_quota: <int>

** Pro Step kann man die default Werte überschreiben:

steps:
    step_a:
        _cluster_submit_options: "..."
        _cluster_pre_job_command: "..."
        _cluster_post_job_command: "..."

*** die default Werte zu überschreiben


!!!
    Die folgende Idee ist schwer umsetzbar. Einzige Möglichkeit wäre das
    Tool checking auf den Cluster Nodes abzustellen. Außerdem benötigt man
    dann zwei module load/unload Kommandos:
    1. eine Version für das Laden von Modulen in Python
    2. eine Version für die BASH
    das bläht die Config auf für wenig bis keinen Mehrwert.
!!!
** Pro Tool sollte es die Möglichkeit geben:
*** ein module load/unload Kommando anzugeben das dann einfach in das
    Submit Skript Template geschrieben wird

Cluster Config als separate YAML Datei (Done)
---------------------------------------------

Die Cluster Config ist aktuell ein hart-kodiertes Dictionary in
pipeline.py, das sollte am besten überführt werden in eine YAML
Konfigurationsdatei. (Hab ich gemacht. CK) Plus Doku.


s2c.py (Sven + Gero) Done
-------------------------

Bitte Error Messages ins Englische übersetzen. (Done by Gero)
Die Lösung mit s2c.py und fix_s2c.py bleibt erhalten. (Done)

Dokumentation (Alexander + Christoph + Sven)
--------------------------------------------

Es wäre super wenn wir eine FAQ Seite für die häufigsten
Fehlermeldungen haben würden (für Alexander aber auch alle anderen).
Die Doku des fastq_source Steps sollte ein Beispiel für ein YAML
dictionary enthalten.
Generell muss die Doku auf fehlenden Inhalt Kontroll gelesen werden.

SHAsum für alle Ausgabedateien (Christoph) (Done)
-------------------------------------------------

Wollen wir das jetzt für alle erzeugten Ausgabedaten. (Done)
SHA1sum für Output Dateien in der Annotation (Done).

Docker (Alexander/Christoph) (Geringste Prio)
---------------------------------------------

Docker Support einbauen mittels Dockerfiles. Sitze ich gerade dran (Christoph).

Pfadangaben für Dateien die aus uap geladen werden (Sven)
---------------------------------------------------------

absolute Pfadangaben für alle open() calls.


Debugging (???)
---------------

Submit Script in Annotation Datei speichern. (Done)
Prosa Log nach STDERR mittels logger 
Evtl. Subcommand fürs zusammensuchen von Ausgabedaten des Runs.

Weitere Ideen
-------------

* Verteilen von uap über PyPI (Python Package Repos)


Mailinglist/GitHub Issue Tracker
--------------------------------

* Vorbereiten das wir für Fehlermeldungen erreichbar sind

Documentation
=============

* FAQ für häufig Fehler
* Problem: steps.rst wird dynamisch durch stepdoc.py erzeugt
* Lösung: conf.py erweitern mit stepdoc.py damit die Doku automatisch aktualisiert wird?
** funktioniert nicht. immer manuell ausführen?
** nicht alle Inhalte sind dann perfekt formatiert, manuelle Bearbeitungen gehen nach dem neu erzeugen verloren
* Verwendung von AbstractStep::runs() beschreiben in Doku anstatt von self.declare_run() und execute()
** http://uap.readthedocs.io/en/latest/extension.html
* Bemerkung zur scheinbar sporadischen Verwendung von fifos, dd usw? Tool abhängige Nutzung von FIFOs
* narrowpeak_to_bed fehlt als Datei in Repository (ist noch bei mit lokal)

Examples
--------

* abändern der Beispiele für neue Version
* zwei Klassen von Beispielen (mit ungefährer CPU-/Speicher-/Dauer-Abschätzung)
** kleine (weniger rechenintensive) Beispiele
** richtige (rechenintensive/speicherhungrige) Beispiele 

Logging
=======

* Fehlermeldungen kürzen
* Stacktrace nur anzeigen wenn log-level auf z.B. debug

Fehler
======

Fehler mit .yaml-out dokumentieren

Steps
=====

* hg19 download reparieren (index_homo_sapiens) einen Download Step erstellen
  für mehrere Dateien/Runs

Umbenennungen/Aufräumen
-----------------------

* TASK in subcommands ändern
* Verzeichnis "old_steps" unter include/steps: Löschen?
* Report Funktionalität entfernen (sollte konzeptionell überdacht werden)
* Notify Funktionalität entfernen
* quotas.yaml entfernen

http://izi-uap.readthedocs.io/en/documentation_review/software-design.html?highlight=task
oder nur ein Beispiel hinzufügen?

Git Repository
==============

### http://uap.readthedocs.io/en/latest/installation.html
"git clone https://github.com/kmpf/uap.git"
	seperates production Repository ohne Branches anbieten?

* Jana Hertel als Owner des finalen Repos

Dateien und Verzeichnisse werden in Abhängigkeit vom Ort, von dem die uap ausgeführt wird, geschrieben... absoluten Dateipfad erzeugen und benutzen?












RNASeq Pipeline Meeting 2014/04/29
----------------------------------

Sven, Jörg, Kristin, Christoph, Micha

Tasks:

- interactive tool to handle big config files might be helpful <least concern>
- add more options to steps with default values which may be adjusted by users
  (for example cufflinks), also add corresponding command line switches
- status.py: add option to skip tool checking, find out why it's so slow (fstat?)
  <solved>
- is it possible to watch a processes' stderr while a step is running?
  - preferably not only if you launched in debug mode, but always, like inter-
  cepting write calls to the respective file descriptor
  - or maybe dump each monitored file's 1024 byte tail every once in a while 
  (this would be easiest and includes stdout and stderr)
- clean up in/ and out/ names - 'error', 'log', 'stderr' should in some cases
  become the same thing
  - we need a well-defined ontology of file types regardless of actual file
  type, more from the semantic perspective

Problems:
- if different sources contain identically named samples they are probably gone
  overwrite there output files handled wrong
  
Sequencing Workflows
====================

Reference Genome
----------------

* Genome Resequencing
** Variant Calling

* Methylome
** Specific alignment (Bisulfite converted bases)
** Methylation calling

* Transcriptome
** De-novo transcript assembly
** Counts per annotation
** Differential expression

* ChIP-seq
** aggregate to peaks
** peak calling (foreground vs background)

Non-reference Genome
--------------------

* Genome
** Genome Assembly

* Transcriptome
** Assemble Transcripts
